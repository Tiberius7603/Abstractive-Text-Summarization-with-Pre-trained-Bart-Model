# Abstractive-Text-Summarization-with-Pre-trained-Bart-Model

Dataset : https://dacon.io/competitions/official/235813/data   
   
Pre-trained Model : https://huggingface.co/gogamza/kobart-base-v2   
   
Evaluation Metrics : F1 Score of ROUGE-1, ROUGE-2, ROUGE-L   
   
Result:   
| data| Score1  | Score2 |Score3|   
|-----|:--------| :------------- | :------------- |   
|**Public**| 0.7717093  | 0.69816425  |0.75071908|   
|**Private**| 0.76925641  | 0.69682126  |0.74600363|   

To do list   
Code modularization     
Modifying Model   


Limitation   

test   
asdfasdf   
